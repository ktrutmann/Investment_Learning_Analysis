---
title: 'Reported Statistics Phase one'
output: 
    html_document:
        toc: true
        toc_float: yes
        code_folding: hide
---

```{r setup, include=FALSE}
library(lme4)
library(lmerTest)
library(lmtest)
library(sandwich)  # For clustered SEs
library(stargazer)
library(MASS) # For ordinal logreg
library(effects)
library(gridExtra)
library(ordinal)
library(tidyverse)

theme_set(theme_minimal())
# Color secifications for the plots
col_set <- c('lightgrey', 'grey', 'darkgrey', 'black')
# col_set <- c('cyan3', 'skyblue4', 'darkblue', 'black')

# Loading data
all_complete_tables <- str_subset(list.files(
  file.path('Output', 'Tables')), 'complete')
most_recent <- max(str_extract(all_complete_tables, '\\d{4}-\\d{2}-\\d{2}'))

complete_table <- read_delim(file.path('Output', 'Tables',
  str_subset(all_complete_tables, most_recent)), delim = ';')

dat_main_long <- read_delim(file.path('..', 'Data', 'Clean',
  'all_participants_long_main_main_study.csv'), delim = ';', guess_max = 5000)
```

The following file presents the analyses as they are reported in the main paper in the order in which they are reported in the paper. The chunk names are also mentioned in the .tex files beside where the results are reported.
This file contains all analyses before and including the reporting of phase one of the experiment. For phase two or the appendix see the other files.


<!-- #################################################################### -->
# Sample Demographics

The study was conducted with **`r nrow(complete_table)`** participants with a mean age
of `r round(mean(complete_table$age), 2)`.
`r sum(complete_table$is_student == 'Ja')` reported being a student.


```{r demographics}
knitr::kable(table(complete_table$gender), col.names = c('Gender', 'Freq.'),
  caption = 'Gender Distribution')

knitr::kable(round(prop.table(table(complete_table$gender)) * 100, 2),
  col.names = c('Gender', 'Prop'), caption = 'Gender Distribution Proportions')

knitr::kable(round(prop.table(table(complete_table$investment_experience)) * 100, 2),
  col.names = c('Investment Experience', 'Proportion'))

round(sum(complete_table$is_student == 'Ja') * 100, 2)

```

Here we show the actual payoff of the participants as well as the average payoff a risk neutral Bayesian agent would have earned. The exchange rate from points to CHF was __.06__. Each "win" in the probability matching task was worth 1 point.
```{r earnings}
earnings <- complete_table %>%
  summarise(avg_earnings = mean(participant_payoff * .06 + 10))

# FIXME: Pretty sure there's something incorrect here!
dat_main_long  %>%
  group_by(participant_code) %>%
  summarize(rational_earnings = sum(price_diff_from_last * rational_hold +
    rational_lottery_earnings, na.rm = TRUE)) %>%
  summarize(rational_earnings = mean(rational_earnings) * .06 + 15 + 10)

  round(2) %>%
  knitr::kable(col.names = c('Average Participant Earnings',
    'Average Earnings Rational Benchmark'))
```

```{r engagement_distribution}
knitr::kable(table(complete_table$engagement),
  col.names = c('Engagement Value', 'Freq'),
  caption = 'Distribution of answers to the "Engagement Question" (7-point Likert-scale)')

median(complete_table$engagement)
```


<!-- #################################################################### -->
# Trading Behavior first phase

What did they do in the very first round where no information was available and how did the portfolios look afterwards?
```{r first_trade}
dat_main_long %>%
  dplyr::filter(i_round_in_block == 0,
    i_block < 2) %>%
  summarize(did_nothing = mean(transaction == 0),
    invested = mean(transaction + hold == 1 & transaction != 0),
    liquidated = mean(transaction + hold == 0 & transaction != 0),
    shorted = mean(transaction + hold == -1 & transaction != 0))

dat_main_long %>%
  dplyr::filter(i_round_in_block == 1,
    i_block < 2) %>%
  summarize(
    invested = mean(hold == 1),
    liquidated = mean(hold == 0),
    shorted = mean(hold == -1))
```

Average holding/shorting frequency (what percentage of the periods did they hold or short the asset on average?):
```{r avg_hold_short}
dat_main_long %>%
  filter(i_block <= 1) %>%
  summarize(average_hold = mean(hold == 1),
    average_short = mean(hold == -1),
    average_rational_hold = mean(rational_hold == 1, na.rm = TRUE),
    average_rational_short = mean(rational_hold == -1, na.rm = TRUE)) %>%
  knitr::kable()
```

Average (and SD) number of transactions in the first phase:
```{r avg_transaction, message = FALSE}
dat_main_long %>%
  filter(i_block <= 1) %>%
  group_by(participant_code) %>%
  summarize(transaction_per_participant = sum(transaction != 0),
    rational_transactions_pp = sum(rational_trade != 0, na.rm = TRUE)) %>%
  summarize(average_transactions = mean(transaction_per_participant),
    average_transaction_sd = sd(transaction_per_participant),
    average_rational_transactions = mean(rational_transactions_pp) + 1,
    average_rational_transactions_sd = sd(rational_transactions_pp)) %>%
  knitr::kable()
```

Average (and SD) number of "jumps" in the first phase:
```{r avg_jumps, message = FALSE}
dat_main_long %>%
  filter(i_block <= 1) %>%
  group_by(participant_code) %>%
  summarize(transaction_per_participant = sum(abs(transaction) == 2)) %>%
  summarize(average_transactions = mean(transaction_per_participant),
    average_transaction_sd = sd(transaction_per_participant)) %>%
  knitr::kable()
```

Average length of an investment period:
```{r avg_inv_length}
dat_prepared <- summarize(complete_table,
  all_avg_hold_length = (avg_hold_length_1 * n_holds_1 +
    avg_hold_length_2 * n_holds_2) / (n_holds_1 + n_holds_2),
  all_avg_short_length = (avg_short_length_1 * n_shorts_1 +
    avg_short_length_2 * n_shorts_2) / (n_shorts_1 + n_shorts_2),
  rational_all_avg_hold_length = (rational_avg_hold_length_1 *
    rational_n_holds_1 + rational_avg_hold_length_2 * rational_n_holds_2) /
    (rational_n_holds_1 + rational_n_holds_2),
  rational_all_avg_short_length = (rational_avg_short_length_1 *
    rational_n_shorts_1 + rational_avg_short_length_2 * rational_n_shorts_2) /
    (rational_n_shorts_1 + rational_n_shorts_2)) %>%
  mutate(all_avg_short_length = replace_na(all_avg_short_length, 0),
  # Excluding those who held almost the whole time:
    all_avg_hold_length = ifelse(
    all_avg_hold_length > 35, NA, all_avg_hold_length),
    all_avg_short_length = ifelse(
      all_avg_short_length > 35, NA, all_avg_short_length))

summarize(dat_prepared,
  avg_hold_length = mean(all_avg_hold_length, na.rm = TRUE),
  sd_hold_lengths = sd(all_avg_hold_length, na.rm = TRUE),
  avg_short_length = mean(all_avg_short_length, na.rm = TRUE),
  sd_short_lengths = sd(all_avg_short_length, na.rm = TRUE)) %>%
knitr::kable()

summarize(dat_prepared,
  rat_avg_hold_len = mean(rational_all_avg_hold_length, na.rm = TRUE),
  rat_sd_hold_len = sd(rational_all_avg_hold_length, na.rm = TRUE),
  rat_avg_short_len = mean(rational_all_avg_short_length, na.rm = TRUE),
  rat_sd_short_len = sd(rational_all_avg_short_length, na.rm = TRUE)) %>%
  knitr::kable()
```

Investing difference in the good vs. bad period:
```{r inv_by_state_table}
this_tab <- dat_main_long %>%
  filter(i_block <= 1) %>%
  group_by(state) %>%
  count(hold) %>%
  pivot_wider(names_from = hold, values_from = n) %>%
  filter(!is.na(state))

  knitr::kable(this_tab)

  chisq.test(this_tab)

```
_(The result is robust to exclusion.)_

This plot looks at the price developments after a trade.
The price movements are flipped for short-sales and for liquidations of short sales (because we want to see what would have happened had they held the short further).

Jumps should be disregarded, as they can have two effects:
Either one counts a jump as the closing and subsequent opening of an investment, in which case they influence both bins symmetrically in oposite directions, or one only regards jumps as opening an investment, which disregards the fact that another investment needs to be given up for it.

Lastly there is the option to only look at the price movements, not the amounts to make the result less dependent on the random character of the magnitude of the price movements.

```{r price_after_trades}
n_shifts <- 2
filtered_df <- dplyr::filter(dat_main_long, i_block < 2)

jumps <- which(abs(filtered_df$transaction) == 2)
# jumps <- numeric() # To exclude jumps
target_moves <- c(which(abs(filtered_df$transaction) != 0), jumps) # Change to != 0 when including jumps

# Jumps get a second entry
moves_after_decision <- tibble(
  original_trade_ix = rep(target_moves, each = n_shifts),
  trade_id = rep(seq_along(target_moves), each = n_shifts),
  target_shift = rep(0:(n_shifts - 1), length(target_moves)),
  was_jump = c(rep(FALSE,
    (length(target_moves) - length(jumps)) * n_shifts),
                rep(TRUE, length(jumps) * n_shifts))) %>%
  mutate(trade_ix = original_trade_ix + target_shift) %>%
  filter(trade_ix < nrow(filtered_df))

full_shift_df <- filtered_df %>%
  dplyr::select(hold, transaction, price, i_block) %>%
  dplyr::slice(moves_after_decision$trade_ix) %>%
  bind_cols(moves_after_decision) %>%
  group_by(trade_id) %>%
  mutate(original_hold = hold[target_shift == 0],
    original_move = transaction[target_shift == 0],
    price_normal = price - price[target_shift == 0], # Normalizing price
    price_normal = case_when(
      original_hold == 0 & original_move == -1 ~ - price_normal,
      original_hold == -1 & !was_jump ~ - price_normal,
      original_hold == 1 & was_jump ~ - price_normal,
      TRUE ~ price_normal),
    trade_direction = case_when(
      original_hold == 0 ~ 'Open',
      was_jump ~ 'Open',
      original_hold != 0 & !was_jump ~ 'Close',
      TRUE ~ 'Close'),
    hold_length = rle(hold)[[1]][2],  # For removing rounds after new trades 
    n_blocks = length(unique(i_block))) %>%  # For removing block overlaps
  mutate(price_normal = sign(price_normal)) %>% # Uncomment for the actual prices, rather than -1 and 1.
  ungroup() %>%
  filter(n_blocks == 1)

dat_prepared <- full_shift_df %>%
  group_by(trade_direction, target_shift) %>%
  summarize(
    avg_price = mean(price_normal),
    se = sd(price_normal) / sqrt(n()),
    ci_upper = avg_price + qt(.95, n()) * se,
    ci_lower = avg_price - qt(.95, n()) * se)

ggplot(dat_prepared,
  aes(x = target_shift, y = avg_price, color = trade_direction)) +
  geom_hline(yintercept = 0, size = .5) +
  geom_line(size = 1.25) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = .025,
    position = position_dodge(.05)) +
  labs(x = 'Periods since Transaction', y = 'Mean Return',
       color = 'Transaction', group = 'Transaction',
       title = 'Phase 1, Excluding Jumps',
       subtitle = 'Ups / Downs coded as 1 / -1') +
  theme(text = element_text(size = 16))
    # values = c('Invest' = 'Black', 'Liquidate' = '#888888')) +

ggsave('price_moves_after_trades_col.pdf',  device = 'pdf',
  width = 10, height = 7, path = file.path('Output', 'Plots'))
```


```{r price_after_rational_trades}
n_shifts <- 20

filtered_df <- dplyr::filter(dat_main_long, i_block < 2)

jumps <- which(abs(filtered_df$rational_trade) == 2)
target_moves <- c(which(abs(filtered_df$rational_trade) != 0), jumps)

# Jumps get a second entry
moves_after_decision <- tibble(
  original_trade_ix = rep(target_moves, each = n_shifts),
  trade_id = rep(seq_along(target_moves), each = n_shifts),
  target_shift = rep(0:(n_shifts - 1), length(target_moves)),
  was_jump = c(rep(FALSE, (length(target_moves) - length(jumps)) * n_shifts),
                rep(TRUE, length(jumps) * n_shifts))) %>%
  mutate(trade_ix = original_trade_ix + target_shift)%>%
  filter(trade_ix < nrow(filtered_df))

full_shift_df <- filtered_df %>%
  dplyr::select(rational_hold, rational_trade, price) %>%
  dplyr::slice(moves_after_decision$trade_ix) %>%
  bind_cols(moves_after_decision) %>%
  group_by(trade_id) %>%
  mutate(original_hold = rational_hold[target_shift == 0],
    original_move = factor(rational_trade[target_shift == 0]),
    price_normal = price - price[target_shift == 0],   # Normalizing price
    price_normal = case_when(
      original_hold == 0 & original_move == -1 ~ - price_normal,
      original_hold == -1 & !was_jump ~ - price_normal,
      original_hold == 1 & was_jump ~ - price_normal,
      TRUE ~ price_normal),
    trade_direction = case_when(
      original_hold == 0 ~ 'Open',
      was_jump ~ 'Open',
      original_hold != 0 & !was_jump ~ 'Close',
      TRUE ~ 'Close'),
    # hold_length = rle(rational_hold)[[1]][2],
    n_blocks = length(unique(i_block))) %>%  # Removing block overlaps
  ungroup() %>%
  filter(n_blocks == 1)

dat_prepared <- full_shift_df %>%
  group_by(trade_direction, target_shift) %>%
  summarize(
    avg_price = mean(price_normal),
    se = sd(price_normal) / sqrt(n()),
    ci_upper = avg_price + qt(.95, n()) * se,
    ci_lower = avg_price - qt(.95, n()) * se)

ggplot(dat_prepared,
  aes(x = target_shift, y = avg_price, color = trade_direction)) +
  geom_hline(yintercept = 0, size = .5) +
  geom_line(size = 1.25) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),
    position = position_dodge(), width = .05) +
  labs(x = 'Periods since Transaction', y = 'Mean Return',
       color = 'Transaction', group = 'Transaction',
       title = 'Phase 1, Bayesian Investor, Including Jumps') +
  theme(text = element_text(size = 16))
    # values = c('Invest' = 'Black', 'Liquidate' = '#888888')) +

ggsave('price_after_rational_trades_col.pdf',  device = 'pdf',
  width = 10, height = 7, path = file.path('Output', 'Plots'))
```

Let's now check how many times participants were correct in either opening or closing investment positions.
"Correct" here means a price increase (decrease) after buying (shorting) and vice versa.

```{r correct_trades}
dat_main_long %>%
  select(hold, transaction, price_diff_to_next,
    position, i_block) %>%
  filter(i_block < 2, transaction != 0) %>%
  mutate(correct_trade = sign(transaction) == sign(price_diff_to_next),
    trade_type = case_when(hold == 0 ~ 'Open',
      abs(transaction) == 2 &
        position == 'Gain' ~ 'Gain Jump',
      abs(transaction) == 2 &
        position == 'Loss' ~ 'Loss Jump',
      abs(transaction) == 2 & position == 'No Returns' ~ 'No Return Jump',
      abs(transaction) == 1 & position == 'Gain' ~ 'Gain Close',
      abs(transaction) == 1 & position == 'Loss' ~ 'Loss Close',
      abs(transaction) == 1 & position == 'No Returns' ~ 'No Returns Close',
      TRUE ~ 'Close')) %>%
  group_by(trade_type) %>%
  summarize(avg_correct_trades = mean(correct_trade),
    n_such_trades = n()) %>%
  ggplot(aes(x = trade_type, y = avg_correct_trades)) +
    geom_bar(stat = 'identity') +
    coord_cartesian(ylim = c(.45, .55))
```

Now we look at their beliefs at the trades.
```{r beliefs_at_trades}
dat_main_long %>%
  filter(abs(transaction) == 1) %>%
  mutate(transaction_type = case_when(
    hold == 0 & transaction == 1 ~ 'Long',
    hold == 0 & transaction == -1 ~ 'Short',
    hold == 1 & position == 'Gain' ~ 'Liq. Long Gain', 
    hold == 1 & position == 'Loss' ~ 'Liq. Long Loss', 
    hold == -1 & position == 'Gain' ~ 'Liq. Short Gain',
    hold == -1 & position == 'Loss' ~ 'Liq. Short Loss')) %>%
  filter(!is.na(transaction_type)) %>%
  group_by(transaction_type) %>%
  summarize(avg_belief = mean(belief),
    sd_belief = sd(belief),
    avg_bayes = mean(bayes_prob_up * 100),
    avg_diff = mean(belief - bayes_prob_up * 100)) %>%
  mutate(across(where(is.numeric), round, 2)) %>%
  knitr::kable()
```

During the first two blocks, participants sold an averarge of
`r round(mean(complete_table$plr_12) * 100, 1)`% of their losses and
`r round(mean(complete_table$pgr_12) * 100, 1)`% of their gains, leading to a DE measure of
__`r round(mean(complete_table$de_12), 3)`__.

Checking whether the DE is larger than the rational benchmark.
```{r DE_test_phase_1}
t.test(complete_table$de_12 - complete_table$rational_de_12,
  alternative = 'greater')
```

```{r event_analysis}
window <- -2:6 # How many periods before and after switch to look at
this_dat <- filter(dat_main_long, i_block < 2)
switches <- which(diff(this_dat$state) != 0) + 2 # Locations of the first period with a new state!
switch_type <- diff(this_dat$state)[diff(this_dat$state) != 0]

moves_around_switches <- tibble(
  original_switch_ix = rep(switches, each = length(window)),
  original_switch_type = as.factor(rep(switch_type, each = length(window))),
  move_id = rep(seq_along(switches), each = length(window)),
  shift = rep(window, length(switches)))  %>%
  mutate(hold_ix = original_switch_ix + shift) %>%
  filter(hold_ix < nrow(this_dat))

this_dat %>%
  dplyr::slice(moves_around_switches$hold_ix) %>%
  bind_cols(moves_around_switches) %>%
  group_by(move_id) %>% 
  mutate(n_blocks = length(unique(i_block))) %>%  # Removing block overlaps
  ungroup() %>%
  filter(n_blocks == 1) %>%
  group_by(original_switch_type, shift) %>%
  summarise(avg_hold = mean(hold, na.rm = TRUE)) %>%

ggplot(aes(x = shift, y = avg_hold, color = original_switch_type,
  group = original_switch_type)) +
  geom_line(size = 1) +
  geom_vline(xintercept = 0, linetype = 'dashed') +
  geom_text(x = 2, y = .255, label = 'Changing from bad to good state',
    color = '#202020', size = 6) +
  geom_text(x = 2, y = .08, label = 'Changing from good to bad state',
    color = '#202020', size = 6) +
  labs(x = 'Rounds, centered around change in asset state',
    y = 'Average Investment',
    group = 'Switch Type', color = 'Switch Type') +
  scale_color_manual(values = c(col_set[1], col_set[3])) +
  scale_x_continuous(breaks = window) +
  theme(panel.grid.minor.x = element_blank(),
    legend.position = 'none',
    text = element_text(size = 16))

ggsave('event_analysis_trades.pdf',  device = 'pdf',
  width = 10, height = 7, path = file.path('Output', 'Plots'))
```


```{r hit_rates}
hit_rates <- complete_table %>%
  mutate(hit_rate = (hit_rate_1 + hit_rate_2) / 2,
    rational_hit_rate = (rational_hit_rate_1 + rational_hit_rate_2) / 2) %>%
  summarize(avg_hit_rate = mean(hit_rate),
    rational_avg_hit_rate = mean(rational_hit_rate))

hit_rates

binom.test(x = as.integer(hit_rates$avg_hit_rate * 150),
  n = 150,
  p = hit_rates$rational_avg_hit_rate,
  alternative = 'less')

max(dat_main_long$i_round_in_block, na.rm = TRUE)

```

<!-- #################################################################### -->
# Results Phase 1

## The Role of Beliefs

### Predictiveness of Beliefs

Ordered logistic regression to determine how predictive beliefs are for investment decisions.
Includes the residuals of beliefs predicted by the bayesian probability.
```{r olog_beliefs}
# Order the levels of hold_lead
dat_prepared <- dat_main_long %>%
    filter(i_block < 2) %>%
    mutate(hold_lead = factor(dplyr::lead(hold),
        levels = c("-1", "0", "1"), ordered = TRUE),
      bayes_prob_up = bayes_prob_up * 100,
      belief_residuals = lm(belief ~ bayes_prob_up)$residuals)

olog_beliefs <- clmm(hold_lead ~ belief + age +
  gender + (1 | participant_code),
  data = dat_prepared)
summary(olog_beliefs)
coeftest(olog_beliefs)
```
_(Robust to exclusion of inattentives!.)_

```{r olog_viz}
# Requires dat_prepared from above!
olog_beliefs <- clmm(hold_lead ~ belief + (1 | participant_code),
  data = dat_prepared)
effect_obj <- Effect(focal.predictors = c('belief'), xlevels = 101,
  olog_beliefs)

effect_obj$prob %>%
  as_tibble() %>%
  mutate(belief = 0:(n() - 1)) %>%
  pivot_longer(cols = -'belief') %>%
  mutate(name = factor(name,
    levels = c('prob.X1', 'prob.X0', 'prob.X.1'),
    labels = c('Holding', 'Not Invested', 'Shorting'))) %>%
  ggplot(aes(belief, value, group = 1)) +
    geom_line(size = 1) +
    facet_grid(rows = vars(name)) +
    labs(x = 'Belief', y = 'Probability') +
    theme(panel.spacing = unit(2, "lines"))

ggsave('olog_prob_predictions.pdf',  device = 'pdf',
  width = 10, height = 7, path = file.path('Output', 'Plots'))
```

The same but focusing on trade decisions with a gain/loss dummy.
```{r olog_beliefs_buy_sell}
# Order the levels of hold_lead
dat_prepared <- dat_main_long %>%
    filter(i_block < 2,
      abs(transaction) == 1) %>%
    mutate(hold_lead = factor(dplyr::lead(hold),
        levels = c("-1", "0", "1"), ordered = TRUE),
    trade_type = if_else(hold == 0, 'Buy', 'Sell'),
    belief = belief / 100)

olog_beliefs_trade <- clmm(hold_lead ~ belief + belief:trade_type +
  (1 | participant_code),
  data = dat_prepared)
coeftest(olog_beliefs_trade)
```

Did higher engagement lead to a "more reasonable" scale in belief reports?
```{r belief_var_by_engagement}
dat_prepared <- dat_main_long %>%
  dplyr::filter(i_block < 2) %>%
  group_by(participant_code, engagement) %>%
  summarize(belief_sd = sd(belief, na.rm = TRUE))

cor.test(dat_prepared$engagement, dat_prepared$belief_sd,
  method = 'spearman')
```

The standard deviation of participants' belief reports ranges from `r sd_tab['Min.']` to `r sd_tab['Max.']` with an average of `r sd_tab['Mean']`.

```{r beliefs_by_states}
t.test(belief ~ state,
  data = filter(dat_main_long, i_block < 2))
```

<!-- -------------------------------------------------------------------- -->
### Belief Formation
Checking whether their beliefs startet at $.5$ at the start of the first two blocks.
```{r belief_start}
start_beliefs <- dat_main_long %>%
  filter(i_round_in_block == 0, i_block < 2) %>%
  pull(belief)

t.test(start_beliefs - 50)
```
On average `r round(mean(start_beliefs == 50) * 100, 2)`% of blocks were started with a belief of $.5$.
The average starting belief was `r round(mean(start_beliefs), 2)`

Numbers about the amount of "inverse updates" in the data.
```{r update_type_table}
dat_main_long %>%
  filter(i_block < 2) %>%
  count(updating_type) %>%
  mutate(percentage = round(n * 100 / sum(n), 2)) %>%
  knitr::kable(caption = 'Was the Update Inverse?')
```

Checking for a difference in overupdating between invested vs. not invested.
```{r updating_diff_invested_not_invested}
dat_prepared <- dat_main_long %>%
  filter(position_end_of_last_period != 'No Returns',
    i_block < 2,
    # updating_type != 'Wrong'
    ) %>%
  mutate(was_invested = position_end_of_last_period != 'Not Invested')

m1 <- lm(belief_diff_bayes_corrected_flipped ~ was_invested,
  data = dat_prepared)
coeftest(m1, vcovCL(m1, cluster = ~dat_prepared$participant_code))
```

How much do they over-update on average?
```{r avg_over_update}
dat_prepared <- dat_main_long %>%
  filter(i_block < 2,
    # position_end_of_last_period == 'Not Invested',
    # position_end_of_last_period %in% c('Gain', 'Loss'),
    # updating_type != 'Wrong'
    )

summarize(dat_prepared,
  avg_update = mean(belief_diff_bayes_corrected_flipped, na.rm = TRUE),
  sd_update = sd(belief_diff_bayes_corrected_flipped, na.rm = TRUE))

m1 <- lm(belief_diff_bayes_corrected_flipped ~ 1,
  data = dat_prepared)
coeftest(m1, vcovCL(m1, cluster = ~dat_prepared$participant_code))
```

Figure showing the baseline updating interaction.
Uncomment the `updating_type != 'Wrong'` in the first filter statement to produce the plot excluding updates in the wrong direction.
```{r updating_baseline_bars, message = FALSE}
dat_prepared <- dat_main_long %>%
  filter(position_end_of_last_period != 'No Returns',
         # updating_type != 'Wrong',
         i_block < 2) %>%
  mutate(target_measure = # belief_bayes_residual)
    belief_diff_bayes_corrected_flipped / 100)

dat_prepared_1 <- dat_prepared %>%
  filter(position_end_of_last_period != 'Not Invested') %>%
  group_by(position_end_of_last_period, price_move_from_last_corrected) %>%
  summarise(mean_update = mean(
              target_measure, na.rm = TRUE),
            SE = sd(target_measure, na.rm = TRUE) /
              sqrt(n()),
            CI_90_lower = mean_update - SE * qt(.95, n()),
            CI_90_upper = mean_update + SE * qt(.95, n()))

dat_prepared_2 <- dat_prepared %>%
  filter(position_end_of_last_period == 'Not Invested') %>%
  summarise(mean_update = mean(
              target_measure, na.rm = TRUE),
            SE = sd(target_measure, na.rm = TRUE) /
              sqrt(n()),
            CI_90_lower = mean_update - SE * qt(.95, n()),
            CI_90_upper = mean_update + SE * qt(.95, n())) %>%
  add_column(tibble(position_end_of_last_period = 'Not Invested',
    price_move_from_last_corrected = ''))

dat_prepared <- full_join(dat_prepared_1, dat_prepared_2)

ggplot(dat_prepared,
       aes(x = position_end_of_last_period, y = mean_update,
           fill = price_move_from_last_corrected)) +
  facet_grid(cols = vars(price_move_from_last_corrected),
    scale = 'free_x', space = 'free_x') +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = CI_90_lower, ymax = CI_90_upper),
                    width = .1, color = tail(col_set, 1)) +
  scale_fill_manual(name = '', values = c(col_set[1:3])) +
  # ylim(0, .3) +
  labs(x = 'Position and Price Move',
    y = 'Average Corrected Belief Update') +
  theme(legend.position = 'none', text = element_text(size = 16))

ggsave('updating_baseline_wrong_included_bars.pdf',  device = 'pdf',
  width = 10, height = 7, path = file.path('Output', 'Plots', 'Bars'))
```


Checking whether there is an interaction in the updating during the first two blocks. These effects are __dummy coded!__ and clustered by participant. Comment out the `updating_type != 'Wrong'` filter to get the results with wrong updates included.
```{r updating_baseline_test}
dat_prepared <- dat_main_long %>%
  filter(i_block < 2,
         position_end_of_last_period %in% c('Gain', 'Loss'),
         # !excluded.x,
         # updating_type != 'Wrong'
         ) %>%
  mutate(price_move_from_last_corrected = dplyr::recode(
      price_move_from_last_corrected, 'Unfavorable' = 0, 'Favorable' = 1),
    position_end_of_last_period = dplyr::recode(
      position_end_of_last_period, 'Loss' = 0, 'Gain' = 1),
    belief_diff_bayes_corrected_flipped = belief_diff_bayes_corrected_flipped / 100) %>%
  left_join(dplyr::select(complete_table, participant_code, ravens_matrices_score),
    by = 'participant_code')

belief_updates_baseline <- lm(belief_diff_bayes_corrected_flipped ~
  position_end_of_last_period * price_move_from_last_corrected + age + gender,
  # position_end_of_last_period : price_move_from_last_corrected : age,
   data = dat_prepared)
coeftest(belief_updates_baseline,
         vcovCL(belief_updates_baseline,
           cluster = ~dat_prepared$participant_code))

summary(belief_updates_baseline)
```
_(robust to excluding inattentives)_

Doing the same test but this time including the Bayesian probability as a predictor to include the "uncorrected" version.
```{r update_baseline_uncorrected_tests}
dat_prepared <- dat_main_long %>%
  filter(i_block < 2,
         updating_type != 'Wrong') %>%
  mutate(inv_dummy = position_end_of_last_period != 'Not Invested',
    price_move = dplyr::recode(
      price_move_from_last_corrected, 'Unfavorable' = 0, 'Favorable' = 1),
    position = dplyr::recode(
      position_end_of_last_period, 'Loss' = 0, 'Gain' = 1, .default = 999),
    bayes_diff_flipped = bayes_diff_flipped * 100)

beliefs_by_inv <- lm(belief_diff_flipped ~
  bayes_diff_flipped * inv_dummy, data = dat_prepared)
coeftest(beliefs_by_inv,
         vcovCL(beliefs_by_inv,
           cluster = ~dat_prepared$participant_code))

beliefs_test_uncor <- lm(belief_diff_flipped ~
  position * price_move + bayes_diff_flipped,
  data = dplyr::filter(dat_prepared, position < 2))
coeftest(beliefs_test_uncor,
         vcovCL(beliefs_test_uncor,
           cluster = ~dplyr::filter(dat_prepared, position < 2)$participant_code))

```

```{r update_differences}
dat_main_long %>%
  filter(i_block < 2,
         position_end_of_last_period %in% c('Gain', 'Loss'),
         # updating_type != 'Wrong'
         ) %>%
  group_by(position_end_of_last_period, price_move_from_last_corrected) %>%
  summarize(mean = mean(belief_diff_bayes_corrected_flipped, na.rm = TRUE),
    sd = sd(belief_diff_bayes_corrected_flipped, na.rm = TRUE))
```

```{r updating_diff_test}
dat_prepared <- dat_main_long %>%
  filter(i_block < 2,
    position_end_of_last_period %in% c('Gain', 'Loss'),
    price_move_from_last_corrected == 'Unfavorable',
    # updating_type != 'Wrong'
    )

m1 <- lm(belief_diff_bayes_corrected_flipped ~ position_end_of_last_period,
  data = dat_prepared)
coeftest(m1, vcovCL(m1, cluster = ~dat_prepared$participant_code))
```


<!-- -------------------------------------------------------------------- -->
### Influence of Beliefs on Trades

```{r beliefs_at_trades}
dat_main_long %>%
  dplyr::filter(abs(transaction) == 1,
    position != 'No Returns',
    i_block < 2) %>%                             
  group_by(transaction, position) %>%
  summarize(avg_belief = mean(belief / 100),
    sd_belief = sd(belief / 100),
    avg_bayes = mean(bayes_prob_up),
    avg_distance_to_bayes = mean(bayes_prob_up - belief / 100))
```

```{r beliefs_at_trades_test}
dat_main_long %>%
  dplyr::filter(abs(transaction) == 1,
    position != 'No Returns',
    i_block < 2,
    transaction == -1,
    position != 'Not Invested'
    ) %>%
  {t.test(.$belief - 50, alternative = 'less')}
```

First we look at the made and forgone profit 3 periods after buys or sales (excluding shorts for now).
```{r forgone_profits}
max_shift <- 3

target_moves <- with(dat_main_long,
  which((hold == 0 & transaction == 1) |
        (hold == 1 & transaction == -1)))

moves_after_decision <- tibble(
  original_move_ix = rep(target_moves, each = max_shift + 1),
  move_id = rep(seq_along(target_moves), each = max_shift + 1),
  target_shift = rep(0:max_shift, length(target_moves)))  %>%
  mutate(move_ix = original_move_ix + target_shift)

dat_main_long %>%
  dplyr::select(hold, transaction, price, bayes_prob_up) %>%
  dplyr::slice(moves_after_decision$move_ix) %>%
  bind_cols(moves_after_decision) %>%
  group_by(move_id) %>%  # Normalizing price
  mutate(price_normal = price - price[target_shift == 0],
    original_move = factor(transaction[target_shift == 0])) %>%
  mutate(n_blocks = length(unique(i_block))) %>%  # Removing block overlaps
  ungroup() %>%
  filter(n_blocks == 1) %>%
  group_by(original_move) %>%
  summarise(avg_move_3 = mean(price_normal[target_shift == max(target_shift)]))

```

Here we test the influence of the beliefs (above Bayes) for the four possible movements:
  
  - Going from no investment into a long investment
  - Going from no invesment into a short investment
  - Selling a long investment (and the interaction between belief and position)
  - Buying back a short investment (and the interaction between belief and position)

```{r logregs_individual}
this_dat <- filter(dat_main_long, i_block < 2) %>%
  mutate(buy = as_factor(transaction > 0),
    sell = as_factor(transaction < 0))

# Buying long
clmm(buy ~ bayes_prob_up + belief +
  (1 | participant_code), link = 'logit',
  data = filter(this_dat, hold == 0)) %>%
  summary()

# Shorting
clmm(sell ~ bayes_prob_up + belief +
  (1 | participant_code),
  link = 'logit', data = filter(this_dat, hold == 0)) %>%
  summary()

# Selling a long position
clmm(sell ~ bayes_prob_up + belief * position +
  (1 | participant_code), link = 'logit',
  data = filter(this_dat, hold == 1, position %in% c('Gain', 'Loss'))) %>%
  summary()

# Selling a short position
clmm(buy ~ bayes_prob_up + belief * position +
  (1 | participant_code), link = 'logit',
  data = filter(this_dat, hold == -1, position %in% c('Gain', 'Loss'))) %>%
  summary()
```


<!-- #################################################################### -->
# Individual Differences

Checking for three-way interactions between position, price move and a third variable. Add the variables `age`, `gender`, `engagement`, `cogn_rpm_total_points` or `risk_soep_general` to the `lm()` call.  
```{r vars_on_belief_updating}
dat_prepared <- dat_main_long %>%
  filter(i_block < 2,
         position_end_of_last_period %in% c('Gain', 'Loss'),
         # updating_type != 'Wrong'
    ) %>%
  mutate(price_move_from_last_corrected = dplyr::recode(
      price_move_from_last_corrected, 'Unfavorable' = -.5, 'Favorable' = .5),
    position_end_of_last_period = dplyr::recode(
      position_end_of_last_period, 'Loss' = -.5, 'Gain' = .5))

belief_updates_baseline <- lm(belief_diff_bayes_corrected_flipped ~
  position_end_of_last_period * price_move_from_last_corrected * risk_soep_general,
   data = dat_prepared)

coeftest(belief_updates_baseline,
         vcovCL(belief_updates_baseline,
           cluster = ~dat_prepared$participant_code))
```

Checks on DE differences.
Put in the following variables from `complete_table`:
`strategy_DE`, `strategy_rational`, `risk_soep_general`, `ravens_matrices_score`, `investment_experience` and `engagement`.

```{r vars_on_de}
cor.test(complete_table$loss_aversion, complete_table$de_12,
  method = 'spearman')
```
```{r age_on_de}
cor.test(complete_table$age, complete_table$de_12)
```
```{r gender_on_de}
t.test(de_12 ~ gender, data = complete_table)
```
```{r strategy_on_payoff}
dat_prepared <- dplyr::select(complete_table, de_12, contains('strategy_'))
all_models <- list()

for (i in seq_len(ncol(dat_prepared) - 1)) {
  this_model <- cor.test(dat_prepared$de_12, pluck(dat_prepared, i + 1),
  method = 'spearman')

  all_models[[i]] <- c(names(dat_prepared)[i + 1], this_model$estimate, this_model$p.value)
  names(all_models[[i]]) <- c('variable', 'rho', 'p_value')
}

bind_rows(all_models) %>%
  mutate(across(rho:p_value, as.numeric),
  rho = round(rho, 2))

```