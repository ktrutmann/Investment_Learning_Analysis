---
title: "Report Pilot"
output:
    html_document:
        toc: true
        toc_float: true
---

# Introduction

## Valuation Models
### Optimal behavior
The optimal behavior is to allocate all resources to the stock with the highest probability of being in the good state. This is because no transaction costs have to be calculated in, and movement is thus completely free in every state. The only scenario in which a future choice space would be dependent on a past action is if all cash had been lost and thus no new stocks could be purchased. However, the only way to decrease the likelihood of this scenario is to optimize the current payoff. Thus the optimal solution for future payouts is also the optimal solution of current payouts.

Given a condition in which an allocation has to be left alone for a fixed amount of trials (e.g. a myopic loss aversion study), the investor would have to calculate the most likely state in each period, which -depending on the transition matrix- could switch at some point. In an environment in which the good state overpowers the bad one, this could lead to investments despite the belief in a good state at time $t$, $q_t$,being below .5.

In the symmetric case, the probabilities of future states never switch, this is because in a matrix of the form 

$$\begin{bmatrix}p & (1-p) \\ (1-p) & p\end{bmatrix}$$

the squaring of said matrix leads to the diagonal entries being $p^2(1-p)^2$, which is $>.5$ for all $p>.5$. Thus, this property is conserved for any power of the matrix.

### Realization Utility
#### Barberis & Xiong, 2012

The model presented in the paper is meant for a continuous time framework with infinite horizon (so "the opposite" of what we are doing). They discribe their price path as

$$\frac{dS_t}{S_t} = (r + \mu) dt + \sigma dZ_t$$

where $r$ is the return of the risk free option, $\mu$ is the "excess return" (so additional to the risk free one) and $Z$ is a brownian motion. Thus there are no "regimes" or states in their model. Question: Why do they write this as a differential in respect to $S_t$ shouldn't it be in respect to $t$?

When an asset is sold, a transaction cost $kW$ is paid. Here $k$ denotes the fraction of the wealth $W$ that must be paid. It is only possible to use $W$ here because they assume that the investor has *all* his wealth in the asset when he decides to sell it.

One source of utility they introduce is from consumption $c$. They define $v(c) = \beta c$ such that $\beta$ indicates linearly how important the consumption is. The second and more important source of utility is selling an asset. They presume that the utility is also generated when another asset is bought right away, which contradicts Frydmann's (2015) rolling mental accounts! The value of selling an asset is $(1 - k)W_t - B_t$, so everything that is not eaten up by transaction costs minus the baseline reference point (which they chose to be "what he would have gotten from the save alternative"). In the first section (we'll see about later) they don't even bother with utility and define $u(x) = x$. So the utility is equal to the value generated by the sale as defined above.

There is allways a probability $\rho$ of experiencing a "liquidity shock" where the investor needs the money from his assets for consumption (e.g. a medical bill in america). This possibility is added as a roundabout way of ensuring that the investor also cares about paper gains and losses. Further it acts as a form of "planing horizon", where a high probability of liquidity shock creates a short horizon. 

They write the value function as $V(W_t, B_t)$ which includes the wealth $W$ and the baseline $B$. They show that this function is *homogenious to degree 1*, which means that if all parameters are multiplied by a number it is the same as if the whole function was multiplied by a number. At the time of buying $W_t = B_t$, and thus they show that if $V(W, W) \geq 0$ for some $W$ it is true for all $W$. Further they assume that the time discound factor $\delta$ is greater than the risk free return $r$. This then leads to the conclusion that all the wealth will always be in some asset, as the risk-free option will not lead to any utility flow.

The decision problem the investor faces is to maximise the value of his currently invested stocks. See formula 10 in the paper (I'm not gonna type that in here). The weird things are that at timepoint $t$ the investor already decides at what time point $\tau$ he is going to sell the asset, and the time of the next liquidity shock $\tau '$ also seems to be known. If he sells the asset before the next liquidity shock he will immediately rebuy another stock, which is why he will get a utility and a new value $V((i - k)W_\tau, B_\tau)$. So in this case he will still have to hold cash when the shock ocurs, but he also got the utility (if the asset in in a gain position).

The investor sells the asset if the relative gain $g_t = W_t/B_t$ reaches a *liquidation point* $g_* \geq 1$.
Here it gets funky, because a utitlity function $U(g_t)$ is introduced but not explained. However the value function is defined as $V(W_t, B_t) = B_t U(g_t)$. Thus, when both sides are divided by $B_t$ we end up with $U(g_t) = V(g_t, 1)$ since $g_t = W_t/B_t$. $U(1)$ gives the amount of utility from having one unit wealth in stocks. It is pretty much the dealbreaker, since if it is above zero, all wealth will be allocated into stocks (according to Steve this is called a "Bangbang" strategy), while all will be held in cash if it is below 0.

Playing aroud with the parameters shows that $U()$ does behave rahter sensibly. Increasing transaction costs $k$ will lead to less overall utility, but especially around the liquidation point a high $k$ introduces a steep drop (since then $k$ actually has to be payed). A higher probability of liquidity shock $\rho$ will just decrease the overall utility. Increasing $\sigma$ leads to increased utility, which would indicate that investors *seek* volatile markets... Similarly, increasing $\mu$ increases the utility, which makes sense. Increasing the effective discount rate $\delta ' = \delta - r$ (discount rate minus returns) lowers the utility a bit. Lastly, increasing the dividend drop-off $\alpha$ increases the utility quite a bit.


If the model is extended to being able to hold multiple stocks, the investor does not care about diversification (which is also a bit unrealistic), since the value of a stock at time 0 is $W_0U(1)$ for one stock and $\sum_1^n W_0U(1)/n$ for $n$ stocks, which is the same.

When analysing their model, they find that traders are risk seeking and are willing to buy stocks with negative expected return, as long as they are volatile enought (as they could then still pass the liquidation point). This sounds a bit like the risky decisions with a goal literature. However, here there is no real goal...
A further problem is that the liquidation point falls to 1 if there are no transaction costs. This means that an investor would immediately sell any gains... That's a problem. Another problem is that the only reason why an investor would sell a paper that is trading at a loss is a liquidity shock. However, in a Lab-study there is no such thing as a liquidity shock, and still people sell some loosing stocks (if reluctantly).


#### Frydman, Barberis et al., 2014
They don't specifically talk about the implementation of the realization utility model here. For example they never explain how they would expect subjects to decide when to buy a stock. The only argument they make is that they will sell a stock if it leads to positive utility right now. Again, without transaction costs this would predict immediate selling of stocks at a gain.


### Prospect Theory
The parameters estimated by K&T would not allow for trading to happen, as people are allways reluctant to buy any shares. In the multi-asset case PT can be implemented in two versions: Either on the *portfolio level* or on the *asset level*. The portfolio level means that only the movement of the portfolio matters, independent of how this movement came about. This would be in line with the *coalescing* propperties of PT. On the portfolio level, the prospect value of each portfolio is calculated and then the asset allocation with the highest combined prospect value is chosen. One effect this distinction leads to is that portfolio level PT considers higher jumps, as a raise in all three portfolios is combined to one big raise. This apparently enhances the effects of prospect theory and leads to a higher disposition effect.

Another difference can be found when giving a choice of either holding one out of two assets or holding a share of both. If the belief about the states are equal (.5), then account wise PT will prefer only holding one (since holding one of each is twice as bad). Portfolio wise PT however will prefer to hold both assets. When looking into this deeper, it can be seen that the probability weighting plays a central role in this effect, since without it PT_portf would reject the holding of two assets even more than PT_acc. Similarly the probability weighting plays a significant role when predicting a one-asset case. If the probability is not distroted, PT will only rarely predict a DE.

Further, account wise PT reacts very sensitively to the $\alpha$ and $\beta$  parameters. The DE measure can range from .74 to -.18 for parameter values of .6 and .88 respectively.

### Argument against prospect theory:
Ben-David,  & Hirshleifer, 2012 find that the point where people are the least likely to sell is around the zero-gain point. Assuming 0 returns as the reference point, people should be willing to sell around that point, because of loss aversion in the loss domain. (p. 2488)


### Transfer of Attention Exchange (TAX)

Assumes "a weighting of events in which attention is transferred between events". It belongs to the class of *configural-weighting models*, which go beyond choices under risk. It includes an *attention exchange function* $\omega(p_k, p_j, K)$ which determines how much attention is shifted from a higher ranking (better) outcome $x_k$ to a lower ranked (worse) oucome $x_j$.

This class of models does not assume *"coalescing"*, which is the melting of identical outcomes. 

The outcomes are ranked from best to worst, unless in the case of pure loss lotteries. There they are ranked from worst to best. Apparently Birnbaum & Bahra (2007) explain why.

In general, the value of each "branch" in a lottery is weighted by a term that depends on the rank of that branch and on its probability.


### Decision field theory

The decision maker draws "mental samples" from the different lotteries. With probability $\pi$ these are drawn in proportion to the outcome probabilities of each lottery arm, and with probability $1 - \pi$ they are drawn uniformly over the lotteries. This mechanism is needed to explain penomena such as the overweighting of small probabilities and can be explained by "temporary failures to keep the actual probabilities in mind". It also helps explain why spliting increases the weight of a lottery arm: Tey are now more likely to be sampled in a uniform sampling round. The outcomes are sampled untill one lottery crosses a decision treshold.

***


## Valuation Model Features
### Gain-Loss seperability:
If I prefer the positive as well as the negative outcomes of lottery $A$ over lottery $B$ seperately, then I should prefer lottery $A$ over $B$ generally. However, many people don't (Birnbaum, 2008)

### Restricted Branch Independence
If two lotteries have one outcome (branch) that is the same (probability and outcome-wise) it should not influence the preferences if this branch is changed in both lotteries. It does (Birnbaum, 2008, Kellen et al., 2018).

## Learning Models
### Dynamic Belief Model
(Zhang et al., 14 from Frydman 17)

It's more of a description of the hothand-fallacy than a learning model:
The decision maker beliefs that the outcome $X_t = X_{t-1}$ with probability $\gamma_t$.
In each trial, $\gamma_t$ is resampled from a uniform distribution $[0, 1]$ with probabiliy $\alpha$.


### Stylized Facts about DE
- Ben-David and Hirshleifer 2012 find a V-shape in buying and selling propensities.
The lowest point is at 0 gain, which goes against PT! They explain the shape partly by traders being more attentive to greater movements. Thus, in our experiment we should not find a V-shape, since they focus their attention on the task.
- Overconfidence may play a role? It may explain the Realization effect (Hishleifer15: 4.2.3)?
- Emotional reappraisal seems to be a remidy against DE (e.g. trading as if it was
somebody elses money; Richards, Fenton-O'Creevy et al., 09)
- People ignore negative feedback to avoid negative emotions (which would lead to risk aversivenes; Kuhnen & Knutson 11)
- Keeping a bad stock could be explained by the enodwment effect. However, Kuhnen and Knutson (2015) found positive feelings about bad stocks, even if the stock had to be rebought every time!

#### Emotion
- Excitement diminishes risk aversion (Kuhnen & Knutson 11; also many sources there) even after fixing beliefs. Would predict a negative DE in the open states.


# Hypothesis

# Results

```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
```


## Descriptive Measures
```{r descriptives, echo=FALSE, message=FALSE}
# descriptives_DE_table <- read_csv('Output//Tables//Descriptives_DE_2019-05-17_test.csv')
# kable(descriptives_DE_table)
# descriptives_RT_table <- read_csv('Output//Tables//Descriptives_RT_2019-05-17_test.csv')
# kable(descriptives_RT_table)
```

# Apendix
## Decision screens
## Individual tables